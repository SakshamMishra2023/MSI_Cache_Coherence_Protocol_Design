# MSI Cache Coherence Protocol Implementation

A complete Verilog RTL implementation of the MSI (Modified-Shared-Invalid) cache coherence protocol for a dual-core system with a two-level cache hierarchy.

---

## ğŸ“‹ Project Overview

This project implements a realistic multi-processor cache coherence system featuring:

- **Two private L1 caches** (32KB each, 4-way set-associative)
- **One shared L2 cache** (128KB, 8-way set-associative)
- **MSI coherence protocol** with snoop-based invalidation
- **Shared bus architecture** with round-robin arbitration
- **Write-back policy** with LRU replacement
- **Comprehensive testbench** with 30+ test scenarios

---

## ğŸ—ï¸ System Architecture



**![Architecture Diagram](tb/image.png "Dual-Core Cache Hierarchy")**

---

## ğŸ¯ MSI Protocol States

### State Definitions

| State | Code | Description | Can Read? | Can Write? |
|-------|------|-------------|-----------|------------|
| **Invalid (I)** | `2'b00` | Line not valid | âŒ | âŒ |
| **Shared (S)** | `2'b01` | Clean, read-only copy | âœ… | âŒ |
| **Modified (M)** | `2'b10` | Dirty, exclusive copy | âœ… | âœ… |

### State Transitions

**[Insert MSI state diagram image here]**

```
I â†’ S : Read miss (BUS_RD)
I â†’ M : Write miss (BUS_RDX)
S â†’ M : Write hit (BUS_UPGR upgrade)
M â†’ S : Snoop read (provide data, downgrade)
M â†’ I : Snoop write (provide data, invalidate)
S â†’ I : Snoop write (invalidate)
```

---

## ğŸšŒ Bus Protocol

### Bus Commands

| Command | Value | Purpose | Data Transfer? |
|---------|-------|---------|----------------|
| `BUS_RD` | `3'b001` | Read, fetch Shared | Yes (64B) |
| `BUS_RDX` | `3'b010` | Read Exclusive, fetch Modified | Yes (64B) |
| `BUS_UPGR` | `3'b011` | Upgrade Sâ†’M | No |
| `BUS_FLUSH` | `3'b100` | Writeback dirty data | Yes (64B) |
| `BUS_IDLE` | `3'b000` | No transaction | No |

### Bus Arbitration
- **Round-robin fairness** between L1 caches
- **Priority-based** for snoop responses
- **Cache-to-cache transfers** for performance optimization


---

## âš™ï¸ Cache Specifications

### L1 Cache
- **Size**: 32KB per cache
- **Associativity**: 4-way set-associative
- **Line Size**: 64 bytes
- **Sets**: 128
- **Policy**: Write-back, write-allocate with MSI coherence

### L2 Cache
- **Size**: 128KB (shared)
- **Associativity**: 8-way set-associative
- **Line Size**: 64 bytes
- **Sets**: 256
- **Policy**: Write-back, write-allocate

### DRAM
- **Latency**: 10 cycles (configurable)
- **Size**: Configurable (default 4MB)

---

## ğŸ§ª Verification Coverage

The testbench includes **30 comprehensive tests** covering:

### State Transition Coverage (100%)
âœ… All 8 MSI transitions  
âœ… Read/write hits and misses  
âœ… Upgrade scenarios  
âœ… Invalidation paths  

### Coherence Scenarios
âœ… Multiple readers (Shared state)  
âœ… Cache-to-cache transfers  
âœ… Snoop-induced transitions  
âœ… False sharing detection  
âœ… Hotspot contention (ping-pong)  

### Edge Cases
âœ… Concurrent accesses  
âœ… Byte-enable patterns (all 16)  
âœ… LRU replacement under saturation  
âœ… Back-to-back requests  
âœ… Race condition handling  

**[Insert coverage report/waveform image here]**

---

## ğŸš€ Getting Started

### Prerequisites
- Verilog simulator (ModelSim, VCS, Icarus Verilog,Vivado etc.)
- GTKWave (for waveform viewing)

### Running Simulation

```bash
# Compile all files
vlog cache_params.vh l1_cache_msi.v new_l2_cache.v dram.v \
     cache_line.v lru_controller.v tb_msi_cache_coherence_enhanced.v

# Run simulation
vsim -c tb_msi_cache_coherence_enhanced -do "run -all"

# View waveforms
gtkwave msi_cache_coherence_enhanced.vcd
```

### Expected Output
```
========================================
Enhanced MSI Cache Coherence Testbench
30 Comprehensive Tests for 100% Coverage
========================================

[TEST 1] Simple Read Miss (I -> S)
[TEST 1] PASS: Read miss handled, data=0x...

[TEST 2] Read Hit in Shared State
[TEST 2] PASS: Read hit in Shared state

...

========================================
Test Summary
========================================
Total Tests: 30
Errors: 0
Warnings: 0

*** ALL TESTS PASSED ***
```

---

## ğŸ“Š Performance Characteristics

### Typical Latencies

| Operation | Latency (cycles) |
|-----------|------------------|
| L1 hit (read/write in M) | 1-2 |
| L1 upgrade (Sâ†’M) | 3-5 |
| L2 hit | 5-10 |
| Cache-to-cache transfer | 3-5 |
| DRAM access | 15-20 |

### Cache-to-Cache Optimization
Without cache-to-cache: **~20 cycles** (writeback + fetch)  
With cache-to-cache: **~5 cycles** (direct transfer)  
**Speedup: 4x faster** 


---

## ğŸ“ Key Features

### 1. **Realistic Coherence Protocol**
- Implements industry-standard MSI protocol
- Snoop-based invalidation for correctness
- Supports multiple readers in Shared state

### 2. **Optimized Data Paths**
- Cache-to-cache transfers (Mâ†’S transitions)
- Upgrade path (Sâ†’M) without data transfer
- Write-back policy reduces memory traffic

### 3. **Robust Verification**
- 30+ directed test scenarios
- State transition monitoring
- Cross-cache data integrity checks
- Performance counter integration

### 4. **Parameterized Design**
- Configurable cache sizes
- Adjustable associativity
- Tunable latencies
- Easy to extend to N cores

---

## ğŸ“ˆ Simulation Results

### Test Statistics
- **Total Tests**: 30
- **State Coverage**: 100% (all MSI transitions)
- **Bus Command Coverage**: 100% (all 5 commands)
- **Byte Enable Coverage**: 100% (all 16 patterns)

### Memory Traffic Analysis
```
DRAM Reads:  X
DRAM Writes: Y
L1 Hit Rate: ~95%
L2 Hit Rate: ~85%
```

**[Insert test result summary image here]**

---

## ğŸ” Notable Test Cases

### TEST 6: Sâ†’M Upgrade
Tests the upgrade path when writing to a Shared line. Verifies `BUS_UPGR` command and invalidation of other sharers.

### TEST 9: Cache-to-Cache Transfer
Demonstrates performance optimization where Modified data transfers directly between L1 caches without touching memory.

### TEST 13: False Sharing
Exposes the performance penalty when two CPUs access different words within the same cache line.

### TEST 20: Hotspot Contention
Stress test showing worst-case "ping-pong" behavior when caches compete for the same line.

---

## ğŸ› ï¸ Design Highlights

### Parallel Snoop Logic
Snoop responses operate independently of the main FSM, ensuring immediate coherence actions without blocking CPU requests.

### Buffer States for Multi-Cycle Transactions
FSM includes buffer states (`BUF_I_TO_S`, `BUF_S_TO_M`, etc.) to handle multi-cycle bus operations while maintaining request context.

### Round-Robin Bus Arbitration
Fair access policy prevents starvation, with last-grant tracking ensuring both caches get equal opportunities.

---

## ğŸ“š Learning Outcomes

This project demonstrates understanding of:
- âœ… Multi-processor cache coherence protocols
- âœ… Snoop-based invalidation mechanisms  
- âœ… Complex FSM design with parallel logic
- âœ… Bus arbitration and shared resource management
- âœ… Write-back cache policies
- âœ… LRU replacement algorithms
- âœ… Comprehensive verification methodology


---

## ğŸ“„ License

This project is open-source and available for educational purposes.

---

## ğŸ‘¤ Author

**Saksham Mishra, Jagan Kumar Tata and Pallav Kumar**  
Computer Architecture Project  

---

## ğŸ™ Acknowledgments

- Design inspiration from modern multi-core processors (Intel, AMD, ARM)
- Verification methodology influenced by industry best practices

---

